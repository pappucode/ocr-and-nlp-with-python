{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5756484c",
   "metadata": {},
   "source": [
    "### Natural Language processing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d6a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268816d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6fb808",
   "metadata": {},
   "source": [
    "##### Basic Terms in NLP and Understand Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578e2a6",
   "metadata": {},
   "source": [
    "#### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f9d5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'how', 'are', 'you', 'doing', 'today', '?']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenizing\n",
    "\n",
    "text = \"Hello, how are you doing today?\"\n",
    "\n",
    "# Tokenize the text into individual words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f89d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', 'How are you?', \"I hope you're doing well.\", 'Have a great day!']\n"
     ]
    }
   ],
   "source": [
    "# Sentence tokenizing\n",
    "#nltk.download('punkt')\n",
    "text = \"Hello! How are you? I hope you're doing well. Have a great day!\"\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc2372",
   "metadata": {},
   "source": [
    "### corpus/corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c3631",
   "metadata": {},
   "source": [
    "###### In NLP, a corpus (plural corpora), corpus refers to a large collection of texts or spoken language data that is used for linguistic analysis and building language models. It serves as a representative sample of a language or domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a2c72",
   "metadata": {},
   "source": [
    "### Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d8904",
   "metadata": {},
   "source": [
    "###### Its mean it is the words and their meaning.for example \"pitch\". For cricket it is the place where bowler throw a ball to batsman. On the other hand, if we tell that this women sound pitch is very high or low. So the word is same but the meaning is different. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac13572",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4e6d448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This stop words exercise python NLTK , Today Monday I Doing task .\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_data = stopwords.words('english')\n",
    "#print(stopwords_data)\n",
    "\n",
    "text = \"This is the stop words exercise in python NLTK, Today is Monday and I am Doing this task.\"\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "#print(words)\n",
    "\n",
    "res = []\n",
    "for word in words:\n",
    "    if word not in stopwords_data:\n",
    "        res.append(word)\n",
    "        res1 = ' '.join(res)        \n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2af3a",
   "metadata": {},
   "source": [
    "## Stemming \n",
    "###### Technique use to find the root/stem of a word\n",
    "###### playing, plays, played => play , cars, car, car's => car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd4a6d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: This Stem: thi\n",
      "Actual: was Stem: wa\n",
      "Actual: the Stem: the\n",
      "Actual: stop Stem: stop\n",
      "Actual: words Stem: word\n",
      "Actual: exercise Stem: exercis\n",
      "Actual: in Stem: in\n",
      "Actual: python Stem: python\n",
      "Actual: NLTK Stem: nltk\n",
      "Actual: , Stem: ,\n",
      "Actual: Today Stem: today\n",
      "Actual: is Stem: is\n",
      "Actual: Monday Stem: monday\n",
      "Actual: and Stem: and\n",
      "Actual: I Stem: i\n",
      "Actual: am Stem: am\n",
      "Actual: Doing Stem: do\n",
      "Actual: this Stem: thi\n",
      "Actual: task Stem: task\n",
      "Actual: . Stem: .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "text = \"This was the stop words exercise in python NLTK, Today is Monday and I am Doing this task.\"\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "\n",
    "for word in words:\n",
    "    print(f\"Actual: {word} Stem: {ps.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba076f37",
   "metadata": {},
   "source": [
    "## N Grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "063bbfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I',), ('I', 'love'), ('I', 'love', 'my'), ('I', 'love', 'my', 'country'), ('I', 'love', 'my', 'country', 'Bangladesh'), ('love',), ('love', 'my'), ('love', 'my', 'country'), ('love', 'my', 'country', 'Bangladesh'), ('my',), ('my', 'country'), ('my', 'country', 'Bangladesh'), ('country',), ('country', 'Bangladesh'), ('Bangladesh',)]\n"
     ]
    }
   ],
   "source": [
    "text = \"I love my country Bangladesh\"\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "#print(list(nltk.bigrams(words)))\n",
    "#print(list(nltk.trigrams(words)))\n",
    "print(list(nltk.everygrams(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8990f",
   "metadata": {},
   "source": [
    "## limmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1024052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studi', 'vaccin', 'peopl', 'hospit']\n",
      "['study', 'vaccine', 'people', 'hospital']\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "text = \"studies vaccines peoples hospital\"\n",
    "\n",
    "# Using Stemming\n",
    "stem = []\n",
    "lema = []\n",
    "for word in nltk.word_tokenize(text):\n",
    "    stem.append(ps.stem(word))\n",
    "    lema.append(wl.lemmatize(word))\n",
    "    \n",
    "print(stem)\n",
    "print(lema)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a4e2e",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "558e6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72b808e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pappu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3203: DtypeWarning: Columns (0,1,2,3,7,8,9,10,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "data_file = pd.read_csv(\"covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5c0bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ᏉᎥ☻լꂅϮ</td>\n",
       "      <td>astroworld</td>\n",
       "      <td>wednesday addams as a disney princess keepin i...</td>\n",
       "      <td>26-05-17 5:46</td>\n",
       "      <td>624.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>18775.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25-07-20 12:27</td>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Basile 🇺🇸</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n",
       "      <td>16-04-09 20:06</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>1677.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>25-07-20 12:27</td>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time4fisticuffs</td>\n",
       "      <td>Pewee Valley, KY</td>\n",
       "      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n",
       "      <td>28-02-09 18:57</td>\n",
       "      <td>9275.0</td>\n",
       "      <td>9525.0</td>\n",
       "      <td>7254.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25-07-20 12:27</td>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethel mertz</td>\n",
       "      <td>Stuck in the Middle</td>\n",
       "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n",
       "      <td>07-03-19 1:45</td>\n",
       "      <td>197.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25-07-20 12:27</td>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIPR-J&amp;K</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>🖊️Official Twitter handle of Department of Inf...</td>\n",
       "      <td>12-02-17 6:45</td>\n",
       "      <td>101009.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25-07-20 12:27</td>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name         user_location  \\\n",
       "0           ᏉᎥ☻լꂅϮ            astroworld   \n",
       "1    Tom Basile 🇺🇸          New York, NY   \n",
       "2  Time4fisticuffs      Pewee Valley, KY   \n",
       "3      ethel mertz  Stuck in the Middle    \n",
       "4         DIPR-J&K     Jammu and Kashmir   \n",
       "\n",
       "                                    user_description    user_created  \\\n",
       "0  wednesday addams as a disney princess keepin i...   26-05-17 5:46   \n",
       "1  Husband, Father, Columnist & Commentator. Auth...  16-04-09 20:06   \n",
       "2  #Christian #Catholic #Conservative #Reagan #Re...  28-02-09 18:57   \n",
       "3  #Browns #Indians #ClevelandProud #[]_[] #Cavs ...   07-03-19 1:45   \n",
       "4  🖊️Official Twitter handle of Department of Inf...   12-02-17 6:45   \n",
       "\n",
       "   user_followers  user_friends  user_favourites user_verified  \\\n",
       "0           624.0         950.0          18775.0         False   \n",
       "1          2253.0        1677.0             24.0          True   \n",
       "2          9275.0        9525.0           7254.0         False   \n",
       "3           197.0         987.0           1488.0         False   \n",
       "4        101009.0         168.0            101.0         False   \n",
       "\n",
       "             date                                               text  \\\n",
       "0  25-07-20 12:27  If I smelled the scent of hand sanitizers toda...   \n",
       "1  25-07-20 12:27  Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2  25-07-20 12:27  @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3  25-07-20 12:27  @brookbanktv The one gift #COVID19 has give me...   \n",
       "4  25-07-20 12:27  25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "\n",
       "                            hashtags               source is_retweet  \n",
       "0                                NaN   Twitter for iPhone      False  \n",
       "1                                NaN  Twitter for Android      False  \n",
       "2                        ['COVID19']  Twitter for Android      False  \n",
       "3                        ['COVID19']   Twitter for iPhone      False  \n",
       "4  ['CoronaVirusUpdates', 'COVID19']  Twitter for Android      False  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d81d421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    if i smelled the scent of hand sanitizers toda...\n",
      "1    hey @yankees @yankeespr and @mlb - wouldn't it...\n",
      "2    @diane3443 @wdunlap @realdonaldtrump trump nev...\n",
      "3    @brookbanktv the one gift #covid19 has give me...\n",
      "4    25 july : media bulletin on novel #coronavirus...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#convert text column to lowercase\n",
    "data_file['text'] = data_file['text'].apply(lambda x: \" \".join(str(x).lower() for x in str(x).split()))\n",
    "print(data_file['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3ab19dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-b47b16f30e40>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_file['text'] = data_file['text'].str.replace('[^\\w\\s]', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    if i smelled the scent of hand sanitizers toda...\n",
       "1    hey yankees yankeespr and mlb  wouldnt it have...\n",
       "2    diane3443 wdunlap realdonaldtrump trump never ...\n",
       "3    brookbanktv the one gift covid19 has give me i...\n",
       "4    25 july  media bulletin on novel coronavirusup...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file['text'] = data_file['text'].str.replace('[^\\w\\s]', '')\n",
    "data_file['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1faea6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81307c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4fafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbe925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e572b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e88b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c860c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47131414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
